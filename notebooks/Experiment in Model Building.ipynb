{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/majid/git/housing/')\n",
    "\n",
    "\n",
    "from collections import defaultdict, OrderedDict\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import pytest\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "\n",
    "from housing_model.data.example import Features, Example\n",
    "from housing_model.data.tf_housing import TfHousing\n",
    "from housing_model.models.keras_model import ModelBuilder, ModelParams, KerasModel, TrainParams\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tfds.load('tf_housing', split='train').take(1).cache()\n",
    "\n",
    "def setup_data(tf_data: tf.data.Dataset, batch_size: int):\n",
    "    input_features = set(tf_data.element_spec.keys())\n",
    "    input_features.remove('metadata')\n",
    "    input_features.remove('sold_price')\n",
    "\n",
    "    return tf_data.map(\n",
    "        lambda ex: (\n",
    "            {f_name: ex[f_name] for f_name in input_features},\n",
    "            ex['sold_price']\n",
    "        )\n",
    "    ).batch(batch_size)\n",
    "\n",
    "train_ds = setup_data(data, batch_size=2)\n",
    "test_ds = setup_data(data, batch_size=1).take(1).map(lambda x, y: x)\n",
    "\n",
    "ex = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'date_end': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([18079.], dtype=float32)>,\n",
      "  'land/depth': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([200.9], dtype=float32)>,\n",
      "  'land/front': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([93.41], dtype=float32)>,\n",
      "  'map/lat': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([44.55023], dtype=float32)>,\n",
      "  'map/lon': <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-79.41331], dtype=float32)>},\n",
      " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([870000.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "pprint(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'date_end'\n",
    "\n",
    "def build_custom_model():\n",
    "    input_feature = tf.keras.layers.Input(name=feature_name, shape=(), dtype='float32')\n",
    "    date_end_reshaped = tf.keras.layers.Reshape((1,), name='to_vector')(input_feature)\n",
    "\n",
    "    emb = []\n",
    "    emb.append(tf.keras.layers.Dense(\n",
    "        units=10, activation='sigmoid', name='emb-0',\n",
    "        kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01)\n",
    "    )(date_end_reshaped))\n",
    "\n",
    "    for i in range(0):\n",
    "        emb.append(tf.keras.layers.Dense(units=10, activation='sigmoid', name=f'emb-{i+1}')(emb[i]))\n",
    "    \n",
    "    sold_price = tf.keras.layers.Dense(units=1, name='sold')(emb[-1])\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_feature, outputs=sold_price)\n",
    "    return model\n",
    "    \n",
    "def build_simple_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(units=10, name=\"feature-dense\", activation='sigmoid'),\n",
    "        tf.keras.layers.Dense(units=1, name=\"output-dense\", activation=None)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_debug_model(model):\n",
    "    debug_outputs = {}\n",
    "\n",
    "    for layer in model.layers:\n",
    "        for (name, tensor) in [\n",
    "            (f'{layer.name}-in', layer.input), \n",
    "            (f'{layer.name}-out', layer.output),\n",
    "        ]:\n",
    "            debug_outputs[name] = tensor\n",
    "\n",
    "\n",
    "    debug_model = tf.keras.Model(inputs={feature_name: input_feature}, outputs=debug_outputs)\n",
    "    return debug_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "feature-dense (Dense)        multiple                  20        \n",
      "_________________________________________________________________\n",
      "output-dense (Dense)         multiple                  11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_model()\n",
    "model.build(input_shape=(1, 1))\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1),\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-51-9e08e5f66923>:1 None  *\n        model.fit(train_ds.map(lambda x, y: (x[feature_name], y)), epochs=100)\n    /Users/majid/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:862 _slice_helper\n        _check_index(s)\n    /Users/majid/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:752 _check_index\n        raise TypeError(_SLICE_TYPE_ERROR + \", got {!r}\".format(idx))\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'date_end'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-9e08e5f66923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     \"\"\"\n\u001b[1;32m   1587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3886\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3888\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   3889\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   3890\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3145\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3146\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2393\u001b[0m     \u001b[0;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[0;32m-> 2395\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2396\u001b[0m     \u001b[0;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2397\u001b[0m     \u001b[0;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3139\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-51-9e08e5f66923>:1 None  *\n        model.fit(train_ds.map(lambda x, y: (x[feature_name], y)), epochs=100)\n    /Users/majid/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:862 _slice_helper\n        _check_index(s)\n    /Users/majid/git/housing/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:752 _check_index\n        raise TypeError(_SLICE_TYPE_ERROR + \", got {!r}\".format(idx))\n\n    TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'date_end'\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds.map(lambda x, y: (x[feature_name], y)), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex in test_ds:\n",
    "    pprint(model(ex))\n",
    "    pprint(debug_model(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('emb-0').weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 0 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[-0.7986613]\n",
      " [-0.8221377]]\n",
      "loss: 5.599822044372559\n",
      "weights: [array([[ 0.5064483 , -0.56430084, -0.25820133, -0.10090905, -0.5163412 ,\n",
      "         0.3539031 , -0.04874986,  0.07362783,  0.08765167, -0.303747  ]],\n",
      "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[ 0.6526663 ,  0.7453051 ,  1.009214  ,  0.6809789 , -0.8829108 ,\n",
      "         0.63363945, -0.31018203,  0.5218337 , -0.7712487 ,  0.29162368]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 0.41663367,  0.47889382,  0.6311691 ,  0.42324862, -0.5642173 ,\n",
      "        0.3988238 , -0.192621  ,  0.32416445, -0.47922152,  0.18289483],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-3.1925998],\n",
      "       [-1.3418946],\n",
      "       [-1.8384826],\n",
      "       [-2.1231544],\n",
      "       [-1.4131674],\n",
      "       [-2.947424 ],\n",
      "       [-2.2197475],\n",
      "       [-2.447199 ],\n",
      "       [-2.473155 ],\n",
      "       [-1.7589602]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-4.620799], dtype=float32)>]\n",
      "----------- 2 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[-0.4789113 ]\n",
      " [-0.49191305]]\n",
      "loss: 4.198404788970947\n",
      "weights: [array([[ 0.49426582, -0.5784482 , -0.2773371 , -0.11368716, -0.49902368,\n",
      "         0.34210497, -0.04237391,  0.06396775,  0.10296164, -0.30909082]],\n",
      "      dtype=float32), array([-0.00775459, -0.00907174, -0.01194275, -0.00792405,  0.01103156,\n",
      "       -0.00740622,  0.00394916, -0.00598677,  0.00949018, -0.00334396],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[ 0.49012595,  0.6031392 ,  0.81284213,  0.5243594 , -0.8147125 ,\n",
      "         0.47078237, -0.3386172 ,  0.377975  , -0.74398655,  0.2016192 ]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 0.30896324,  0.38399884,  0.5036771 ,  0.32264528, -0.51377016,\n",
      "        0.29284835, -0.20809035,  0.23233071, -0.4576729 ,  0.12516129],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-2.728141 ],\n",
      "       [-1.1203132],\n",
      "       [-1.5353575],\n",
      "       [-1.7945914],\n",
      "       [-1.2390878],\n",
      "       [-2.5142612],\n",
      "       [-1.9208987],\n",
      "       [-2.0827208],\n",
      "       [-2.1606264],\n",
      "       [-1.4956309]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([-3.9708242], dtype=float32)>]\n",
      "----------- 1000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.2478   ]\n",
      " [1.7685703]]\n",
      "loss: 0.0574822723865509\n",
      "weights: [array([[ 0.5243767 , -0.7978417 , -0.6172267 , -0.30380043,  0.1494015 ,\n",
      "         0.3755232 ,  0.38601714,  0.06363799,  0.66549635, -0.3730791 ]],\n",
      "      dtype=float32), array([-0.05120669,  0.10012832,  0.02582852, -0.01976794,  0.05420849,\n",
      "       -0.03830318,  0.01019579, -0.02059525, -0.05473211,  0.00258609],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-0.00820283,  0.01213954,  0.01894141,  0.01532916, -0.03186545,\n",
      "        -0.00765309, -0.02221365, -0.00017619, -0.02255308,  0.01079253]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 3.2950044e-03, -1.7356366e-02, -1.1952931e-02, -2.6892666e-03,\n",
      "        3.2701902e-03,  1.6656853e-03,  5.3985938e-03,  1.3933488e-05,\n",
      "        1.7120704e-02, -2.4428060e-03], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-0.01639904],\n",
      "       [ 0.03997642],\n",
      "       [ 0.03507867],\n",
      "       [ 0.02346564],\n",
      "       [ 0.00054054],\n",
      "       [-0.01069593],\n",
      "       [-0.01066869],\n",
      "       [ 0.00468481],\n",
      "       [-0.02033173],\n",
      "       [ 0.02663485]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0163703], dtype=float32)>]\n",
      "----------- 2000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0999335]\n",
      " [1.9076012]]\n",
      "loss: 0.009262118488550186\n",
      "weights: [array([[ 0.5865307 , -0.8817731 , -0.74254495, -0.4211716 ,  0.34571752,\n",
      "         0.43385133,  0.5268234 ,  0.05869089,  0.8004575 , -0.4637575 ]],\n",
      "      dtype=float32), array([-0.08031275,  0.24235654,  0.12947977,  0.00744815,  0.02350902,\n",
      "       -0.05315468, -0.03682914, -0.02015764, -0.19086087,  0.02818521],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-0.00410955,  0.00521689,  0.0073807 ,  0.00782715, -0.01080937,\n",
      "        -0.00390104, -0.00799386,  0.00069762, -0.00731184,  0.0064384 ]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 2.2082697e-03, -1.0210797e-02, -7.7652596e-03, -2.3106607e-03,\n",
      "        2.4519740e-03,  1.1398499e-03,  3.5256697e-03, -6.3725689e-05,\n",
      "        9.4752554e-03, -2.2026729e-03], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-0.00684688],\n",
      "       [ 0.01794904],\n",
      "       [ 0.01617511],\n",
      "       [ 0.01181461],\n",
      "       [-0.00295721],\n",
      "       [-0.00467493],\n",
      "       [-0.00588397],\n",
      "       [ 0.00248586],\n",
      "       [-0.00952596],\n",
      "       [ 0.0125329 ]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00753474], dtype=float32)>]\n",
      "----------- 3000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0338023]\n",
      " [1.968819 ]]\n",
      "loss: 0.0010574234183877707\n",
      "weights: [array([[ 0.6125566 , -0.91447693, -0.78764313, -0.4707546 ,  0.41029164,\n",
      "         0.45872432,  0.57509726,  0.05337421,  0.84424466, -0.5052654 ]],\n",
      "      dtype=float32), array([-0.09508879,  0.30939367,  0.1811886 ,  0.02364543,  0.00682233,\n",
      "       -0.06083129, -0.06028966, -0.01966434, -0.25225055,  0.0436519 ],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-0.00146298,  0.00182655,  0.00245145,  0.00278437, -0.00343044,\n",
      "        -0.00140802, -0.00259264,  0.00034895, -0.00233784,  0.0023683 ]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 8.7587908e-04, -3.9046099e-03, -3.0507287e-03, -1.0019150e-03,\n",
      "        1.0034693e-03,  4.5802363e-04,  1.3830019e-03, -3.2756361e-05,\n",
      "        3.5302760e-03, -9.5774466e-04], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-0.00238894],\n",
      "       [ 0.00634053],\n",
      "       [ 0.0057304 ],\n",
      "       [ 0.00428567],\n",
      "       [-0.00132016],\n",
      "       [-0.0016677 ],\n",
      "       [-0.00217677],\n",
      "       [ 0.00091707],\n",
      "       [-0.00342756],\n",
      "       [ 0.00447761]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00262129], dtype=float32)>]\n",
      "----------- 4000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0106193]\n",
      " [1.9902097]]\n",
      "loss: 0.00010430958354845643\n",
      "weights: [array([[ 0.6213211 , -0.9254147 , -0.8021838 , -0.48742023,  0.43048647,\n",
      "         0.46718082,  0.59041405,  0.05118375,  0.8580456 , -0.51950836]],\n",
      "      dtype=float32), array([-0.10042888,  0.33306524,  0.19975777,  0.02984013,  0.00067892,\n",
      "       -0.06363039, -0.06870502, -0.01945808, -0.27356264,  0.04957464],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-0.00046634,  0.00058192,  0.00076619,  0.00088575, -0.00105603,\n",
      "        -0.00045105, -0.0008037 ,  0.00012187, -0.00072387,  0.00076055]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 2.89105927e-04, -1.27447827e-03, -1.00366003e-03, -3.39968596e-04,\n",
      "        3.33905453e-04,  1.51897606e-04,  4.54702764e-04, -1.15058065e-05,\n",
      "        1.14267215e-03, -3.25097819e-04], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-0.00075981],\n",
      "       [ 0.00202128],\n",
      "       [ 0.00182746],\n",
      "       [ 0.00137539],\n",
      "       [-0.00044574],\n",
      "       [-0.00053447],\n",
      "       [-0.00070334],\n",
      "       [ 0.0002959 ],\n",
      "       [-0.00110022],\n",
      "       [ 0.00143113]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00082898], dtype=float32)>]\n",
      "----------- 5000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0032538]\n",
      " [1.9970009]]\n",
      "loss: 9.790866897674277e-06\n",
      "weights: [array([[ 0.624066  , -0.9288404 , -0.80668074, -0.4926321 ,  0.43666995,\n",
      "         0.46983808,  0.59512526,  0.05045661,  0.8622885 , -0.52399   ]],\n",
      "      dtype=float32), array([-0.10213985,  0.34059483,  0.20569465,  0.03186058, -0.00129949,\n",
      "       -0.06453007, -0.07139432, -0.01938938, -0.28030476,  0.05150686],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-1.4346311e-04,  1.7902703e-04,  2.3431581e-04,  2.7228240e-04,\n",
      "        -3.2147992e-04, -1.3898905e-04, -2.4518097e-04,  3.8519214e-05,\n",
      "        -2.2078480e-04,  2.3444931e-04]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 8.99546576e-05, -3.95156094e-04, -3.11934389e-04, -1.06682361e-04,\n",
      "        1.04148174e-04,  4.73401160e-05,  1.41304656e-04, -3.64670632e-06,\n",
      "        3.53381911e-04, -1.02021499e-04], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-2.3353705e-04],\n",
      "       [ 6.2222965e-04],\n",
      "       [ 5.6261220e-04],\n",
      "       [ 4.2424281e-04],\n",
      "       [-1.3927976e-04],\n",
      "       [-1.6461988e-04],\n",
      "       [-2.1716487e-04],\n",
      "       [ 9.1554830e-05],\n",
      "       [-3.3919024e-04],\n",
      "       [ 4.4090458e-04]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00025475], dtype=float32)>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- 6000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0009891]\n",
      " [1.9990877]]\n",
      "loss: 9.052926657204807e-07\n",
      "weights: [array([[ 0.6249065 , -0.929889  , -0.80805147, -0.49422652,  0.43854994,\n",
      "         0.47065222,  0.5965599 ,  0.05023013,  0.8635803 , -0.5253631 ]],\n",
      "      dtype=float32), array([-0.10266718,  0.34291065,  0.20752306,  0.03248665, -0.00191011,\n",
      "       -0.06480761, -0.07222247, -0.01936799, -0.2823748 ,  0.05210562],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-4.3776599e-05,  5.4770586e-05,  7.1453716e-05,  8.3032224e-05,\n",
      "        -9.7737007e-05, -4.2413041e-05, -7.4618569e-05,  1.1839441e-05,\n",
      "        -6.7303015e-05,  7.1560542e-05]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 2.74145641e-05, -1.20409153e-04, -9.50964750e-05, -3.25712754e-05,\n",
      "        3.17253725e-05,  1.44190599e-05,  4.30428045e-05, -1.10938799e-06,\n",
      "        1.07581145e-04, -3.11550102e-05], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-7.1615679e-05],\n",
      "       [ 1.8928070e-04],\n",
      "       [ 1.7112403e-04],\n",
      "       [ 1.2901574e-04],\n",
      "       [-4.3105392e-05],\n",
      "       [-5.0639501e-05],\n",
      "       [-6.6720706e-05],\n",
      "       [ 2.7530914e-05],\n",
      "       [-1.0389445e-04],\n",
      "       [ 1.3404863e-04]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7.677078e-05], dtype=float32)>]\n",
      "----------- 7000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0003004]\n",
      " [1.999723 ]]\n",
      "loss: 8.349854851985583e-08\n",
      "weights: [array([[ 0.6251618 , -0.9302088 , -0.8084688 , -0.49471158,  0.43912014,\n",
      "         0.4709002 ,  0.59699476,  0.05016088,  0.86397326, -0.5257816 ]],\n",
      "      dtype=float32), array([-0.10282783,  0.3436156 ,  0.20808025,  0.0326777 , -0.00209622,\n",
      "       -0.06489213, -0.07247479, -0.01936142, -0.2830047 ,  0.0522884 ],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-1.3294404e-05,  1.6625483e-05,  2.1683212e-05,  2.5215562e-05,\n",
      "        -2.9655486e-05, -1.2883394e-05, -2.2643515e-05,  3.6048827e-06,\n",
      "        -2.0417116e-05,  2.1737025e-05]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 8.3415380e-06, -3.6619113e-05, -2.8928611e-05, -9.9197605e-06,\n",
      "        9.6574840e-06,  4.3889231e-06,  1.3095476e-05, -3.3857668e-07,\n",
      "        3.2710865e-05, -9.4881070e-06], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-2.1726170e-05],\n",
      "       [ 5.7521647e-05],\n",
      "       [ 5.2005667e-05],\n",
      "       [ 3.9220846e-05],\n",
      "       [-1.3085737e-05],\n",
      "       [-1.5358528e-05],\n",
      "       [-2.0247462e-05],\n",
      "       [ 8.3911145e-06],\n",
      "       [-3.1539545e-05],\n",
      "       [ 4.0745617e-05]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.336502e-05], dtype=float32)>]\n",
      "----------- 8000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0000919]\n",
      " [1.9999163]]\n",
      "loss: 7.725340367414901e-09\n",
      "weights: [array([[ 0.6252411 , -0.930307  , -0.8085955 , -0.49486   ,  0.4392937 ,\n",
      "         0.47097582,  0.59712785,  0.05013983,  0.8640893 , -0.5259074 ]],\n",
      "      dtype=float32), array([-0.10287682,  0.34382895,  0.2082492 ,  0.03273559, -0.00215252,\n",
      "       -0.06491774, -0.07255126, -0.01935929, -0.28319645,  0.05234371],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-3.8997377e-06,  4.6733530e-06,  6.2403415e-06,  7.4422987e-06,\n",
      "        -8.7660719e-06, -3.8080952e-06, -6.6492266e-06,  1.0731808e-06,\n",
      "        -5.8331389e-06,  6.4088745e-06]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 2.6372932e-06, -1.1414382e-05, -9.0509548e-06, -3.1735190e-06,\n",
      "        3.1089357e-06,  1.4105635e-06,  4.1470184e-06, -1.1901591e-07,\n",
      "        1.0216925e-05, -3.0261717e-06], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-5.8308142e-06],\n",
      "       [ 1.7794866e-05],\n",
      "       [ 1.6124772e-05],\n",
      "       [ 1.2300607e-05],\n",
      "       [-3.2458120e-06],\n",
      "       [-3.9396000e-06],\n",
      "       [-5.3842596e-06],\n",
      "       [ 3.1278942e-06],\n",
      "       [-8.7803091e-06],\n",
      "       [ 1.2757679e-05]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([8.225441e-06], dtype=float32)>]\n",
      "----------- 9000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0000284]\n",
      " [1.9999723]]\n",
      "loss: 7.849223493394675e-10\n",
      "weights: [array([[ 0.6252542 , -0.930338  , -0.8086401 , -0.4949034 ,  0.43934602,\n",
      "         0.4710013 ,  0.5971716 ,  0.05013347,  0.86413145, -0.5259487 ]],\n",
      "      dtype=float32), array([-0.10289094,  0.3438911 ,  0.20829967,  0.0327525 , -0.00216908,\n",
      "       -0.06492603, -0.07257428, -0.01935887, -0.28325152,  0.05235993],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-1.4888449e-06,  2.1439464e-06,  2.5927989e-06,  2.7602291e-06,\n",
      "        -3.2233811e-06, -1.4030807e-06, -2.5231243e-06,  3.8333732e-07,\n",
      "        -2.5000891e-06,  2.3897705e-06]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 6.7170504e-07, -3.1731970e-06, -2.4609890e-06, -7.4844183e-07,\n",
      "        7.0100077e-07,  3.2174501e-07,  1.0450178e-06, -1.0758271e-08,\n",
      "        2.8042800e-06, -7.2868966e-07], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-3.1844211e-06],\n",
      "       [ 5.1651232e-06],\n",
      "       [ 4.6195555e-06],\n",
      "       [ 3.2911948e-06],\n",
      "       [-2.2900076e-06],\n",
      "       [-2.5042627e-06],\n",
      "       [-3.0379997e-06],\n",
      "       [ 1.6789272e-08],\n",
      "       [-4.1865133e-06],\n",
      "       [ 3.4476620e-06]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([7.1525574e-07], dtype=float32)>]\n",
      "----------- 10000 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0000169]\n",
      " [1.999984 ]]\n",
      "loss: 2.708588908717502e-10\n",
      "weights: [array([[ 0.6252542 , -0.930338  , -0.8086401 , -0.49493313,  0.43937582,\n",
      "         0.4710013 ,  0.5971716 ,  0.05012975,  0.86413145, -0.5259487 ]],\n",
      "      dtype=float32), array([-0.10289839,  0.34392092,  0.2083168 ,  0.03275954, -0.00217534,\n",
      "       -0.06492603, -0.07258173, -0.01935887, -0.28328133,  0.05236675],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-8.0602797e-07,  1.0766271e-06,  1.3544291e-06,  1.5131050e-06,\n",
      "        -1.7735699e-06, -7.7143409e-07, -1.3694432e-06,  2.1370846e-07,\n",
      "        -1.2896003e-06,  1.3070578e-06]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 4.4195315e-07, -1.9945403e-06, -1.5645999e-06, -5.1344114e-07,\n",
      "        4.9304913e-07,  2.2483516e-07,  6.9147927e-07, -1.3927973e-08,\n",
      "        1.7741870e-06, -4.9419555e-07], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-1.4999805e-06],\n",
      "       [ 3.1765705e-06],\n",
      "       [ 2.8597144e-06],\n",
      "       [ 2.1099368e-06],\n",
      "       [-9.9432600e-07],\n",
      "       [-1.1220172e-06],\n",
      "       [-1.4151292e-06],\n",
      "       [ 2.8414524e-07],\n",
      "       [-2.0714742e-06],\n",
      "       [ 2.1987744e-06]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([9.536743e-07], dtype=float32)>]\n",
      "----------- 10001 -----------\n",
      "tf.Tensor(\n",
      "[[1]\n",
      " [2]], shape=(2, 1), dtype=int32)\n",
      "label: [[1]\n",
      " [2]]\n",
      "pred: [[1.0000169]\n",
      " [1.999984 ]]\n",
      "loss: 2.708588908717502e-10\n",
      "weights: [array([[ 0.6252542 , -0.930338  , -0.8086401 , -0.49493316,  0.43937585,\n",
      "         0.4710013 ,  0.5971716 ,  0.05012975,  0.86413145, -0.5259487 ]],\n",
      "      dtype=float32), array([-0.1028984 ,  0.34392095,  0.20831682,  0.03275954, -0.00217535,\n",
      "       -0.06492603, -0.07258174, -0.01935887, -0.28328136,  0.05236675],\n",
      "      dtype=float32)]\n",
      "grad = [<tf.Tensor: shape=(1, 10), dtype=float32, numpy=\n",
      "array([[-8.0602808e-07,  1.0766271e-06,  1.3544291e-06,  1.5131041e-06,\n",
      "        -1.7735699e-06, -7.7143409e-07, -1.3694432e-06,  2.1370849e-07,\n",
      "        -1.2896003e-06,  1.3070578e-06]], dtype=float32)>, <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 4.4195315e-07, -1.9945403e-06, -1.5645999e-06, -5.1344159e-07,\n",
      "        4.9304913e-07,  2.2483516e-07,  6.9147927e-07, -1.3927959e-08,\n",
      "        1.7741870e-06, -4.9419555e-07], dtype=float32)>, <tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
      "array([[-1.4999805e-06],\n",
      "       [ 3.1765705e-06],\n",
      "       [ 2.8597144e-06],\n",
      "       [ 2.1099372e-06],\n",
      "       [-9.9432600e-07],\n",
      "       [-1.1220172e-06],\n",
      "       [-1.4151292e-06],\n",
      "       [ 2.8414524e-07],\n",
      "       [-2.0714742e-06],\n",
      "       [ 2.1987744e-06]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([9.536743e-07], dtype=float32)>]\n",
      "new weights: [array([[ 0.6252542 , -0.930338  , -0.8086401 , -0.4949332 ,  0.43937588,\n",
      "         0.4710013 ,  0.5971716 ,  0.05012974,  0.86413145, -0.5259487 ]],\n",
      "      dtype=float32), array([-0.1028984 ,  0.34392098,  0.20831683,  0.03275954, -0.00217535,\n",
      "       -0.06492603, -0.07258175, -0.01935887, -0.2832814 ,  0.05236676],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model = build_simple_model()\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices([1, 2]).map(lambda x: (x, x)).batch(2)\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2)\n",
    "\n",
    "iter_print = 10000\n",
    "repeat_cnt = iter_print + 2\n",
    "\n",
    "for idx, (x, y_true) in enumerate(train_ds.repeat(repeat_cnt)):\n",
    "    y_true = tf.expand_dims(y_true, -1)\n",
    "    x = tf.expand_dims(x, -1)\n",
    "\n",
    "#     trainable_variables = [y_pred]\n",
    "#     layer_names = ['y_pred']\n",
    "#     for layer in model.layers:\n",
    "#         trainable_variables.append(layer.trainable_variables)\n",
    "#         layer_names.append(layer.name)\n",
    "\n",
    "#    grads = tape.gradient(loss, trainable_variables)\n",
    "    \n",
    "#     layers_output = debug_model(x)\n",
    "#     for layer_name, layer_grad in zip(layer_names, grads):\n",
    "#         if layer_name != 'y_pred':\n",
    "#             print(f'*** {layer_name} **')\n",
    "#             print(f'weights:\\n{model.get_layer(layer_name).weights}')\n",
    "#             print(f'layer inputs:\\n{layers_output.get(layer_name+\"-in\")}')\n",
    "#             print(f'layer outputs:\\n{layers_output.get(layer_name+\"-out\")}')\n",
    "#         print(f'grad:\\n{layer_grad}\\n\\n')\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(x, training=True)\n",
    "        loss = loss_fn(y_true, y_pred)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    if idx > iter_print or idx % 1000 == 0:\n",
    "        print(f\"----------- {idx} -----------\")\n",
    "        print(x)\n",
    "\n",
    "        print(f'label: {y_true.numpy()}\\npred: {y_pred.numpy()}')\n",
    "        print(f'loss: {loss.numpy().mean()}')\n",
    "        print(f'weights: {model.layers[0].get_weights()}')\n",
    "        print(f'grad = {grads}')\n",
    "    \n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    \n",
    "    if idx > iter_print:\n",
    "        print(f'new weights: {model.layers[0].get_weights()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
