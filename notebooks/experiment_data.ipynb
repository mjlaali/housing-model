{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfds.load('tf_housing', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date_end': <tf.Tensor: shape=(), dtype=float32, numpy=18079.0>, 'land/depth': <tf.Tensor: shape=(), dtype=float32, numpy=200.9>, 'land/front': <tf.Tensor: shape=(), dtype=float32, numpy=93.41>, 'map/lat': <tf.Tensor: shape=(), dtype=float32, numpy=44.55023>, 'map/lon': <tf.Tensor: shape=(), dtype=float32, numpy=-79.41331>, 'metadata': {'ml_num': <tf.Tensor: shape=(), dtype=string, numpy=b'206287'>}, 'sold_price': <tf.Tensor: shape=(), dtype=float32, numpy=870000.0>}\n"
     ]
    }
   ],
   "source": [
    "a_sample = train_ds.take(1)\n",
    "for an_ex in a_sample:\n",
    "    print(an_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = train_ds.batch(batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'date_end': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([18079., 18045., 18225., 18186., 18023., 18074., 17926., 18135.,\n",
      "       18071., 17973.], dtype=float32)>, 'land/depth': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([200.9 ,   1.  , 109.  , 111.77, 116.  , 156.  , 130.27, 115.  ,\n",
      "        59.  ,   1.  ], dtype=float32)>, 'land/front': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 93.41,   1.  ,  75.  ,  49.21, 118.01,  17.67,  72.83,  25.  ,\n",
      "       129.  ,   1.  ], dtype=float32)>, 'map/lat': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([44.55023 , 43.50414 , 44.11433 , 43.89475 , 43.6678  , 43.68098 ,\n",
      "       43.51707 , 44.205917, 43.79596 , 43.641026], dtype=float32)>, 'map/lon': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([-79.41331, -79.87949, -79.11518, -79.24115, -79.54058, -79.28829,\n",
      "       -79.61995, -77.39651, -79.28582, -79.55904], dtype=float32)>, 'metadata': {'ml_num': <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
      "array([b'206287', b'W4450810', b'N4595018', b'N4525209', b'W4427947',\n",
      "       b'E4461790', b'W4245680', b'X4550826', b'E4428843', b'W4365942'],\n",
      "      dtype=object)>}, 'sold_price': <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
      "array([ 870000.,  458600.,  800000.,  950000., 2300000., 1055000.,\n",
      "       1975000.,  355000.,  860000.,  410000.], dtype=float32)>}\n"
     ]
    }
   ],
   "source": [
    "for a_batch in batches.take(1):\n",
    "    print(a_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GeneratorState',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_add_variable_with_custom_getter',\n",
       " '_apply_options',\n",
       " '_as_serialized_graph',\n",
       " '_buffer_size',\n",
       " '_checkpoint_dependencies',\n",
       " '_consumers',\n",
       " '_deferred_dependencies',\n",
       " '_flat_shapes',\n",
       " '_flat_structure',\n",
       " '_flat_types',\n",
       " '_functions',\n",
       " '_gather_saveables_for_checkpoint',\n",
       " '_graph',\n",
       " '_graph_attr',\n",
       " '_handle_deferred_dependencies',\n",
       " '_has_captured_ref',\n",
       " '_input_dataset',\n",
       " '_inputs',\n",
       " '_list_extra_dependencies_for_serialization',\n",
       " '_list_functions_for_serialization',\n",
       " '_lookup_dependency',\n",
       " '_maybe_initialize_trackable',\n",
       " '_name_based_attribute_restore',\n",
       " '_name_based_restores',\n",
       " '_no_dependency',\n",
       " '_object_identifier',\n",
       " '_preload_simple_restoration',\n",
       " '_restore_from_checkpoint_position',\n",
       " '_self_name_based_restores',\n",
       " '_self_setattr_tracking',\n",
       " '_self_unconditional_checkpoint_dependencies',\n",
       " '_self_unconditional_deferred_dependencies',\n",
       " '_self_unconditional_dependency_names',\n",
       " '_self_update_uid',\n",
       " '_setattr_tracking',\n",
       " '_shape_invariant_to_type_spec',\n",
       " '_single_restoration_from_checkpoint_position',\n",
       " '_tf_api_names',\n",
       " '_tf_api_names_v1',\n",
       " '_trace_variant_creation',\n",
       " '_track_trackable',\n",
       " '_tracking_metadata',\n",
       " '_type_spec',\n",
       " '_unconditional_checkpoint_dependencies',\n",
       " '_unconditional_dependency_names',\n",
       " '_update_uid',\n",
       " '_variant_tensor',\n",
       " '_variant_tensor_attr',\n",
       " '_variant_tracker',\n",
       " 'apply',\n",
       " 'as_numpy_iterator',\n",
       " 'batch',\n",
       " 'cache',\n",
       " 'concatenate',\n",
       " 'element_spec',\n",
       " 'enumerate',\n",
       " 'filter',\n",
       " 'flat_map',\n",
       " 'from_generator',\n",
       " 'from_tensor_slices',\n",
       " 'from_tensors',\n",
       " 'interleave',\n",
       " 'list_files',\n",
       " 'map',\n",
       " 'options',\n",
       " 'padded_batch',\n",
       " 'prefetch',\n",
       " 'range',\n",
       " 'reduce',\n",
       " 'repeat',\n",
       " 'shard',\n",
       " 'shuffle',\n",
       " 'skip',\n",
       " 'take',\n",
       " 'unbatch',\n",
       " 'window',\n",
       " 'with_options',\n",
       " 'zip']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['date_end', 'land/depth', 'land/front', 'map/lat', 'map/lon', 'metadata', 'sold_price'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
